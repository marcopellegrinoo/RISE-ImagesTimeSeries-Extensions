{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***SpatialTemporal-RISE***\n",
        "\n",
        "In this notebook, we delve into the ST-RISE framework, an extension of the original RISE method, which aims to provide interpretability for machine learning models in the context of spatiotemporal data. The ST-RISE approach focuses on understanding the influence of input features over time and space, particularly in applications where temporal dynamics play a critical role.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "The primary objectives of ST-RISE are:\n",
        "\n",
        "1. **Temporal Sensitivity**: To analyze how model predictions vary with changes in input features across different time steps.\n",
        "2. **Spatial Relevance**: To evaluate the significance of spatial patterns in influencing model outputs, enabling a better understanding of local feature importance.\n",
        "3. **Integration of Temporal and Spatial Information**: To combine the insights from both spatial and temporal perspectives, providing a comprehensive view of the model's behavior.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "The ST-RISE method builds upon the existing RISE framework by incorporating a two-dimensional Gaussian noise generation process that considers both spatial and temporal aspects of the input data. This allows for the creation of saliency maps that highlight the most influential features at each time step while accounting for their spatial relationships.\n",
        "\n",
        "In the following sections, we will explore the implementation details, conduct experiments using the ST-RISE framework, and analyze the results to assess the effectiveness of this method in providing insights into model predictions.\n",
        "\n",
        "## Structure of the Notebook\n",
        "\n",
        "- **Data Preparation**: Loading and preprocessing the spatiotemporal dataset.\n",
        "- **ST-RISE Implementation**: Detailed steps to implement the ST-RISE methodology.\n",
        "- **Results Analysis**: Visualizing and interpreting the saliency videos generated by the ST-RISE framework.\n",
        "- 4. **Evaluation** of the saliency videos using **Insertion** and **Deletion** metrics.\n",
        "\n",
        "By the end of this notebook, we aim to enhance our understanding of model interpretability in spatiotemporal contexts and demonstrate the utility of the ST-RISE approach in achieving this goal.\n"
      ],
      "metadata": {
        "id": "iS_JFCab5Q1y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbZ_uuYH0YWA"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "\n",
        "# Specify the TensorFlow version used\n",
        "# TensorFlow 2.15.0 is chosen for compatibility with Keras and other dependencies.\n",
        "!pip install tensorflow==2.15.0  # cuDNN 8.9, CUDA 12.2\n",
        "!pip install keras==2.15.0  # Keras for high-level neural networks\n",
        "# General libraries for data manipulation and numerical computations\n",
        "!pip install numpy==1.25.2  # Fundamental package for numerical computing\n",
        "!pip install pandas==2.0.3  # Data manipulation and analysis\n",
        "# Libraries for handling spatial and raster data\n",
        "!pip install rioxarray==0.15.5  # Raster I/O with xarray\n",
        "!pip install rasterio==1.3.10  # Reading and writing raster datasets\n",
        "!pip install geopandas==0.13.2  # Geospatial data manipulation\n",
        "# Libraries for data visualization\n",
        "!pip install matplotlib==3.7.1  # Comprehensive library for static, animated, and interactive visualizations\n",
        "!pip install seaborn==0.13.1  # Statistical data visualization based on Matplotlib\n",
        "!pip install matplotlib_scalebar==0.8.1  # Adds a scale bar to Matplotlib plots\n",
        "!pip install adjustText==1.1.1  # Helps adjust text in Matplotlib for better readability\n",
        "# Libraries for scientific computing and handling NetCDF data\n",
        "!pip install xarray==2023.7.0  # N-D array support with labeled axes\n",
        "!pip install netCDF4==1.6.5  # Reading and writing NetCDF files\n",
        "!pip install cftime==1.6.3  # Provides time handling capabilities\n",
        "# Other useful libraries\n",
        "!pip install imageio==2.31.6  # For reading and writing image data\n",
        "!pip install cmasher==1.8.0  # Colormaps for Matplotlib\n",
        "!pip install great-circle-calculator==1.3.1  # Calculate great circle distances between points\n",
        "!pip install geopy==2.4.1  # For geocoding and distance calculations\n",
        "!pip install scipy==1.11.4  # Scientific and technical computing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "import sys\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras import activations\n",
        "import numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "ZVBXTcMCO02q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "id": "HEc-pj3VtsVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Loading Data from Google Drive***"
      ],
      "metadata": {
        "id": "MbD0Z7yGPXxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### ***Loading Data from Google Drive***\n",
        "\n",
        "# Define the base path for data storage in Google Drive\n",
        "# Change the base_path to point to the correct directory where your data is stored\n",
        "base_path = \"./MyDrive/Water_Resources/\"\n",
        "\n",
        "# Specify different subdirectories for various data and model types\n",
        "data_path = base_path + \"data/training_validation_test_splits\"  # Path for training, validation, and test data\n",
        "model_path = base_path + \"trained_models/\"  # Path for trained models\n",
        "modules_path = base_path + \"python_modules/\"  # Path for additional Python modules\n",
        "xai_path = base_path + \"XAI/\"  # Path for XAI-related resources\n",
        "results_path = xai_path + \"results/\"  # Path for storing results from XAI analysis"
      ],
      "metadata": {
        "id": "6aisaSVzPdDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT DATA FOR VOTTIGNASCO\n",
        "\n",
        "# Paths to the .npy files containing the data for Vottignasco\n",
        "v_test_OHE_path = data_path + '/Vottignasco_00425010001_test_month_OHE.npy'  # One-Hot Encoded test data\n",
        "v_test_image_path = data_path + '/Vottignasco_00425010001_test_normalized_image_sequences.npy'  # Normalized image sequences for testing\n",
        "v_test_target_dates_path = data_path + '/Vottignasco_00425010001_test_target_dates.npy'  # Target dates for the test data\n",
        "\n",
        "# Load the NumPy arrays from the specified .npy files\n",
        "vottingasco_test_OHE = np.load(v_test_OHE_path)  # Load One-Hot Encoded data\n",
        "vottignasco_test_image = np.load(v_test_image_path)  # Load normalized image sequences\n",
        "vottignasco_test_dates = np.load(v_test_target_dates_path)  # Load target dates for the test set\n"
      ],
      "metadata": {
        "id": "ksZzSRlOPoJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0IYifx-dWgE",
        "outputId": "964120f3-6abe-40e3-f2eb-15710ddf322c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105\n",
            "105\n",
            "105\n"
          ]
        }
      ],
      "source": [
        "print(len(vottignasco_test_dates))\n",
        "print(len(vottignasco_test_image))\n",
        "print(len(vottingasco_test_OHE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWG_CmOUdcmT",
        "outputId": "3d0487fd-5632-4e56-b986-4a2601f5c5ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] \n",
            "\n",
            "[[[-0.55874205 -0.63231546 -1.0530392 ]\n",
            "  [-0.62497324 -0.24734885 -0.95617104]\n",
            "  [-0.64852315 -0.29456472 -1.0120971 ]\n",
            "  [-0.6475669   0.01120646 -0.9414161 ]\n",
            "  [-0.6483382   0.04486901 -0.9291374 ]\n",
            "  [-0.64837635  0.21673024 -0.7445328 ]\n",
            "  [-0.6482272   0.01929929 -0.9028175 ]\n",
            "  [-0.64826417 -0.35680774 -0.71746933]]\n",
            "\n",
            " [[-0.56017417 -0.30140942 -1.0722721 ]\n",
            "  [-0.6341238  -0.3249078  -1.1285268 ]\n",
            "  [-0.64822614 -0.2947506  -0.9674306 ]\n",
            "  [-0.6474924   0.08621608 -0.8394658 ]\n",
            "  [-0.6481902   0.17821798 -0.8374907 ]\n",
            "  [-0.64775074  0.14878109 -0.8802751 ]\n",
            "  [-0.6477138   0.09261598 -1.0055645 ]\n",
            "  [-0.64804226  0.06027458 -1.1226149 ]]\n",
            "\n",
            " [[-0.64782256 -0.32245472 -1.1192324 ]\n",
            "  [-0.64856017 -0.17655824 -0.96336424]\n",
            "  [-0.64591223 -0.43483806 -1.0460285 ]\n",
            "  [-0.6466841   0.08755382 -0.7752676 ]\n",
            "  [-0.6481902   0.13593481 -0.814374  ]\n",
            "  [-0.64730966  0.05031955 -0.93223447]\n",
            "  [-0.6470899   0.0145226  -0.98568094]\n",
            "  [-0.64782363  0.03042608 -0.9392518 ]]\n",
            "\n",
            " [[-0.6353699  -0.76991665 -1.2733611 ]\n",
            "  [-0.6447015  -1.1339542  -1.4570495 ]\n",
            "  [-0.6479346  -0.3430685  -0.93998206]\n",
            "  [-0.6479335  -0.05842897 -0.7758751 ]\n",
            "  [-0.64771265 -0.0111102  -0.772695  ]\n",
            "  [-0.64767736 -0.05486056 -0.9103228 ]\n",
            "  [-0.6476387  -0.07690503 -0.96165144]\n",
            "  [-0.6478595   0.00875339 -0.944221  ]]\n",
            "\n",
            " [[-0.5813335  -0.5919675  -1.1580268 ]\n",
            "  [-0.63551897 -0.47076115 -1.0262413 ]\n",
            "  [-0.6484492   0.19985415 -0.59008545]\n",
            "  [-0.6473831   0.03852554 -0.8635086 ]\n",
            "  [-0.6473819  -0.05430289 -0.9271889 ]\n",
            "  [-0.64782363 -0.13684103 -1.0742605 ]\n",
            "  [-0.64767563 -0.11166299 -1.0550044 ]\n",
            "  [-0.6477867  -0.04560261 -1.1002485 ]]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Visualize the data for Vottignasco\n",
        "\n",
        "# Display the One-Hot Encoded representation of the first instance in the test set\n",
        "print(vottingasco_test_OHE[0], \"\\n\")  # One-Hot Encoding of seasons for the first test instance\n",
        "\n",
        "# Display the normalized image of the first instance in the test set\n",
        "print(vottignasco_test_image[0][0], \"\\n\")  # Normalized image sequence for the first test instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Models Loading***"
      ],
      "metadata": {
        "id": "h7yDUFnoQCr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# If you want to load the entire model, dropout_custom layer has to be defined:\n",
        "\n",
        "mc_dropout = True\n",
        "\n",
        "# Definizione della classe personalizzata doprout_custom\n",
        "class doprout_custom(tf.keras.layers.SpatialDropout1D):\n",
        "    def call(self, inputs, training=None):\n",
        "        if mc_dropout:\n",
        "            return super().call(inputs, training=True)\n",
        "        else:\n",
        "            return super().call(inputs, training=False)"
      ],
      "metadata": {
        "id": "yDi23OvBQFMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the paths of the ensemble models for Vottignasco in Google Drive\n",
        "import os\n",
        "\n",
        "# Define the base directory for the Vottignasco models\n",
        "base_dir = model_path + \"seq2val/Vottignasco\"  # Directory containing the models\n",
        "lstm_suffix = 'time_dist_LSTM'  # Suffix used to identify LSTM model files\n",
        "\n",
        "# Initialize lists to store model and weight paths\n",
        "vott_lstm_models = []  # List to store paths of LSTM models\n",
        "vott_lstm_weights = []  # List to store paths of model weights\n",
        "\n",
        "def extract_index(filename):\n",
        "    \"\"\"Function to extract the final index from the filename.\"\"\"\n",
        "    return int(filename.split('_')[-1].split('.')[0])  # Extracts the numeric index from the filename\n",
        "\n",
        "# Traverse the directory and add relevant files to their respective lists\n",
        "for root, _, files in os.walk(base_dir):\n",
        "    for filename in files:\n",
        "        full_path = os.path.join(root, filename)  # Get the full path of the file\n",
        "        if lstm_suffix in filename:  # Check if the file is an LSTM model\n",
        "            if filename.endswith(\".keras\"):  # Check for model files\n",
        "                vott_lstm_models.append(full_path)  # Add model path to the list\n",
        "            else:  # Otherwise, it's a weights file\n",
        "                vott_lstm_weights.append(full_path)  # Add weights path to the list\n",
        "\n",
        "# Sort the model and weight paths based on the extracted index from the filenames\n",
        "vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))  # Sort models\n",
        "vott_lstm_weights = sorted(vott_lstm_weights, key=lambda x: extract_index(os.path.basename(x)))  # Sort weights\n"
      ],
      "metadata": {
        "id": "wwDrl5QfQPcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of paths for the loaded models and weights\n",
        "vott_lstm_models_loaded = []  # List to store the loaded Vottignasco LSTM models\n",
        "racc_lstm_models_loaded = []  # (Assuming this will be used later for another set of models)\n",
        "\n",
        "# Loop to load the LSTM models\n",
        "for i in range(10):\n",
        "    print(f\"Loading LSTM models {i+1}\")  # Indicate the loading progress of LSTM models\n",
        "\n",
        "    # Load VOTTIGNASCO model\n",
        "    model_lstm_path = vott_lstm_models[i]  # Get the path for the current LSTM model\n",
        "    # Load the CNN+LSTM model using the specified path\n",
        "    model = load_model(model_lstm_path, custom_objects={\"doprout_custom\": doprout_custom})  # Load the model with custom objects\n",
        "    # Append the loaded model to the list of loaded models\n",
        "    vott_lstm_models_loaded.append(model)  # Add the loaded model to the list\n"
      ],
      "metadata": {
        "id": "JEcy1d55QQUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r6PBXkE03RO",
        "outputId": "7722f257-52be-4696-d5ce-81fa86e2d4a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.engine.functional.Functional at 0x7903b227f9a0>,\n",
              " <keras.src.engine.functional.Functional at 0x7903abf13fa0>,\n",
              " <keras.src.engine.functional.Functional at 0x7903b227f7c0>,\n",
              " <keras.src.engine.functional.Functional at 0x7903abfeff70>,\n",
              " <keras.src.engine.functional.Functional at 0x7903a03568f0>,\n",
              " <keras.src.engine.functional.Functional at 0x7903a02900a0>,\n",
              " <keras.src.engine.functional.Functional at 0x7903b0a1bac0>,\n",
              " <keras.src.engine.functional.Functional at 0x7903abfece20>,\n",
              " <keras.src.engine.functional.Functional at 0x7903a0099480>,\n",
              " <keras.src.engine.functional.Functional at 0x79038c731600>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "vott_lstm_models_loaded"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***SPATIAL-TEMPORAL RISE***"
      ],
      "metadata": {
        "id": "J3GPgj4e6gwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***3D Gaussian Noise***"
      ],
      "metadata": {
        "id": "AySVJdcR6pSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_noise_slice(noise, time_step=0):\n",
        "    # Assumes that noise has the shape (time_steps, height, width, 3)\n",
        "    # Extract the corresponding channel for visualization\n",
        "    noise_slice = noise[time_step, :, :, 0]  # Select the first channel for simplicity\n",
        "    # Display the extracted noise slice using a colormap\n",
        "    plt.imshow(noise_slice, cmap='jet', vmin=-1, vmax=+1.0)\n",
        "    # Set the title of the plot to indicate the time step being visualized\n",
        "    plt.title(f'Noise at time step {time_step}')\n",
        "    # Add a colorbar to provide a reference for the color scale\n",
        "    plt.colorbar()\n",
        "    # Show the plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4oMVglT26qSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mean_noise_over_time(noise):\n",
        "    # Calculate the mean noise intensity over height, width, and channels\n",
        "    mean_noise = np.mean(noise, axis=(1, 2, 3))  # Mean across height, width, and channels\n",
        "    # Plot the mean noise intensity against time steps\n",
        "    plt.plot(mean_noise)\n",
        "    # Set the title of the plot\n",
        "    plt.title('Mean Noise over Time')\n",
        "    # Label the x-axis as 'Time step'\n",
        "    plt.xlabel('Time step')\n",
        "    # Label the y-axis as 'Mean Noise Intensity'\n",
        "    plt.ylabel('Mean Noise Intensity')\n",
        "    # Display the plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "9cAvXplA7LjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Generate Masks: Gaussian-3D Noise***"
      ],
      "metadata": {
        "id": "2gTzmBNF7cD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_perturbation(shape, center, sigma_t=50, sigma_x=1.0, sigma_y=1.0):\n",
        "    # Unpack the shape tuple into individual dimensions\n",
        "    time_steps, height, width, channels = shape\n",
        "    t_center, h_center, w_center = center\n",
        "\n",
        "    # Define the mean vector (μ) representing the center of the noise\n",
        "    mu = np.array([t_center, h_center, w_center])\n",
        "\n",
        "    # Covariance matrix for the three dimensions\n",
        "    sigma = np.array([\n",
        "        [sigma_t, 0, 0],  # Variance along the time dimension\n",
        "        [0, sigma_x, 0],  # Variance along the height dimension\n",
        "        [0, 0, sigma_y]   # Variance along the width dimension\n",
        "    ])\n",
        "\n",
        "    # Calculate the inverse of the covariance matrix (Σ^−1)\n",
        "    sigma_inv = np.linalg.inv(sigma)\n",
        "\n",
        "    # Generate 3D coordinates\n",
        "    x_coords, y_coords, z_coords = np.meshgrid(\n",
        "        np.arange(time_steps), np.arange(height), np.arange(width), indexing='ij'\n",
        "    )\n",
        "\n",
        "    # Flatten the coordinates for easier calculations\n",
        "    positions = np.vstack([x_coords.ravel(), y_coords.ravel(), z_coords.ravel()]).T\n",
        "\n",
        "    # Calculate the multivariate Gaussian for each point\n",
        "    diff = positions - mu  # Difference from the mean\n",
        "    exponent = -0.5 * np.sum(diff @ sigma_inv * diff, axis=1)  # Exponent term for the Gaussian\n",
        "\n",
        "    # Reshape to obtain the original shape (time_steps, height, width)\n",
        "    noise_3D = np.exp(exponent).reshape(time_steps, height, width)\n",
        "\n",
        "    return noise_3D  # Return the generated Gaussian noise\n"
      ],
      "metadata": {
        "id": "VQiqrF-M7c8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_masks_gaussian3D(N, shape, sigma_t, sigma_x, sigma_y):\n",
        "    # Unpack the shape tuple into individual dimensions\n",
        "    time_steps, height, width, channels = shape\n",
        "    # Initialize an array to hold the generated masks\n",
        "    masks = np.zeros((N, time_steps, height, width))\n",
        "\n",
        "    # Generate N masks\n",
        "    for i in tqdm(range(N), desc='Generating masks'):\n",
        "        beta = random.choice([-1, 1])  # Randomly choose a sign for the noise (positive or negative)\n",
        "\n",
        "        # Randomly select the center coordinates for the Gaussian perturbation\n",
        "        t_center = np.random.randint(0, 104)\n",
        "        h_center = np.random.randint(0, 5)\n",
        "        w_center = np.random.randint(0, 8)\n",
        "        center = (t_center, h_center, w_center)\n",
        "\n",
        "        # Generate 3D Gaussian noise based on the selected center\n",
        "        noise_3D = gaussian_perturbation(shape, center, sigma_t, sigma_x, sigma_y)\n",
        "\n",
        "        # Adjust the sign of the noise based on beta\n",
        "        if (beta == 1):\n",
        "            noise_3D = np.abs(noise_3D)  # Make all values positive\n",
        "        else:\n",
        "            noise_3D = -np.abs(noise_3D)  # Make all values negative\n",
        "\n",
        "        # Store the generated noise in the masks array\n",
        "        masks[i] = noise_3D\n",
        "\n",
        "    return masks  # Return the array of generated masks\n"
      ],
      "metadata": {
        "id": "-Mg75kAA7l1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum the generated mask to the specified channel at each time step\n",
        "def additive_gaussianNoise_onechannel(images, masks, index_feat_to_perturb):\n",
        "    masked = []  # Initialize a list to store the masked images\n",
        "\n",
        "    # Iterate over all the N generated masks\n",
        "    for mask in masks:\n",
        "        masked_images = copy.deepcopy(images)  # Create a deep copy of the original images\n",
        "\n",
        "        # Perturb only the specified channel\n",
        "        masked_images[..., index_feat_to_perturb] = np.add(\n",
        "            masked_images[..., index_feat_to_perturb],\n",
        "            mask  # Add the mask to the specified channel of the images\n",
        "        )\n",
        "\n",
        "        masked.append(masked_images)  # Append the perturbed images to the list\n",
        "\n",
        "    return masked  # Return the list of masked images"
      ],
      "metadata": {
        "id": "W2ArDGEv7wxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***RISE-3D***"
      ],
      "metadata": {
        "id": "XNtzknAE7091"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_predict(models, images, x3_exp):\n",
        "    # Check the type of images; if it's a list, get the length for the ensemble\n",
        "    if type(images) == list:\n",
        "        len_x3 = len(images)  # Number of masked images\n",
        "    else:\n",
        "        len_x3 = 1  # Only one image provided\n",
        "        images = np.expand_dims(images, axis=0)  # Expand dimensions to match expected input shape\n",
        "\n",
        "    # Prepare the input for the ensemble model\n",
        "    Y_test = np.stack(images)  # Stack images into a NumPy array\n",
        "    Y_test_x3 = np.tile(x3_exp, (len_x3, 1, 1))  # Duplicate x3_exp for each image\n",
        "\n",
        "    # Initialize a list to collect predictions from each model\n",
        "    all_preds = []\n",
        "\n",
        "    # Iterate through the models and gather predictions\n",
        "    for model in models:  # Use the models passed as a parameter\n",
        "        preds = model.predict([Y_test, Y_test_x3], verbose=0)  # Make predictions\n",
        "        all_preds.append(preds)  # Store predictions\n",
        "\n",
        "    # Convert the list of predictions into a NumPy array for easier mean calculation\n",
        "    all_preds_array = np.array(all_preds)\n",
        "\n",
        "    # Calculate the mean predictions across all models (along axis 0)\n",
        "    mean_preds = np.mean(all_preds_array, axis=0)\n",
        "\n",
        "    return mean_preds  # Return the mean predictions"
      ],
      "metadata": {
        "id": "bKh-hUZz70SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_saliency_map(preds_array, masks):\n",
        "    \"\"\"\n",
        "    Calculate the mean saliency map given a series of predictions and masks.\n",
        "\n",
        "    :param preds_array: Array of predictions (number of masks x prediction dimensions).\n",
        "    :param masks: Array of masks (number of masks x mask dimensions).\n",
        "    :return: Mean saliency map.\n",
        "    \"\"\"\n",
        "    sal = []  # Initialize a list to store saliency calculations for each mask\n",
        "    for j in range(len(masks)):\n",
        "        sal_i = preds_array[j] * np.abs(masks[j])  # Element-wise multiplication of predictions and the absolute mask\n",
        "        sal.append(sal_i.reshape(-1, 5, 8))  # Reshape to match the original frame format\n",
        "\n",
        "    # Remove extra dimensions to allow np.mean along axis=0. masks has shape (N, 5, 8, 1)\n",
        "    masks_squeezed = np.squeeze(np.abs(masks))\n",
        "    # Now calculate the mean along axis 0\n",
        "    ev_masks = np.mean(masks_squeezed, axis=0)\n",
        "\n",
        "    # Calculate the saliency map as the mean saliency weighted by the inverse of the mean masks\n",
        "    sal = (1 / ev_masks) * np.mean(sal, axis=0)\n",
        "\n",
        "    return sal  # Return the computed mean saliency map\n"
      ],
      "metadata": {
        "id": "N0WnPZFC7-Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explain(models, x1, x3, generate_masks_func, apply_mask_func,\n",
        "            index_feat_to_perturb=None, N=1000, sigma_t=100.0, sigma_spatial=1.0, input_size=(104, 5, 8, 3)):\n",
        "    \"\"\"\n",
        "    Implementation of RISE (Randomized Input Sampling for Explanation)\n",
        "\n",
        "    :param models: List of pretrained models.\n",
        "    :param x1: Input images.\n",
        "    :param x3: One-hot encoded input.\n",
        "    :param generate_masks_func: Function to generate masks.\n",
        "    :param apply_mask_func: Function to apply masks to images.\n",
        "    :param index_feat_to_perturb: Indices of features to perturb.\n",
        "    :param N: Maximum number of masks to generate.\n",
        "    :param sigma_t: Sigma for temporal dimension in mask generation.\n",
        "    :param sigma_x: Sigma for spatial dimension in mask generation.\n",
        "    :param sigma_y: Sigma for spatial dimension in mask generation.\n",
        "    :param input_size: Size of the input.\n",
        "    :return: Saliency Video.\n",
        "    \"\"\"\n",
        "\n",
        "    # Original prediction without masks\n",
        "    pred_original = ensemble_predict(models, x1, x3)  # Average predictions from the ensemble\n",
        "    #print(\"original pred:\", pred_original)\n",
        "\n",
        "    # Generate and apply Gaussian masks\n",
        "    masks = generate_masks_func(N, input_size, sigma_t, sigma_x=sigma_spatial, sigma_y=sigma_spatial)\n",
        "    masked_images = apply_mask_func(x1, masks, index_feat_to_perturb)\n",
        "\n",
        "    # Predictions on perturbed images with the ensemble\n",
        "    preds_masked = ensemble_predict(models, masked_images, x3)\n",
        "    #print(\"pred_masked:\", preds_masked)\n",
        "\n",
        "    # Calculate the absolute difference between original and masked predictions\n",
        "    diff_pred = [abs(pred_original - pred_masked) for pred_masked in preds_masked]\n",
        "    #print(\"diff_pred:\", diff_pred)\n",
        "\n",
        "    # Concatenate the difference predictions along the specified axis\n",
        "    weights_array = np.concatenate(diff_pred, axis=0)\n",
        "\n",
        "    # Calculate the initial saliency map based on the weights\n",
        "    sal = calculate_saliency_map(weights_array, masks)\n",
        "\n",
        "    # The final saliency map is stored in `sal`\n",
        "    print(\"Processo completato.\", \"\\n\")\n",
        "    print(\"Mappa di salienza finale:\")\n",
        "    print(sal)\n",
        "    return sal  # Return the calculated saliency map\n"
      ],
      "metadata": {
        "id": "4m93-O-K8HAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Evaluation: Insertion and Deletion***"
      ],
      "metadata": {
        "id": "gpXvcTo8Rgag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calculate_auc(x, y):\n",
        "    \"\"\"\n",
        "    Calcola l'area sotto la curva (AUC) utilizzando il metodo del trapezio.\n",
        "\n",
        "    :param x: Valori dell'asse x (frazione dei pixel inseriti).\n",
        "    :param y: Valori dell'asse y (errori calcolati).\n",
        "    :return: Area sotto la curva.\n",
        "    \"\"\"\n",
        "    return np.trapz(y, x)"
      ],
      "metadata": {
        "id": "A0Om3uMQRhJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Returns an array structured as [value, [t, x, y]] with pixels ordered by importance\n",
        "def get_flatten_saliency_video_ordered_by_importance(saliency_video):\n",
        "    # Flatten the saliency video to a 1D array\n",
        "    flatten_saliency_video = saliency_video.flatten()\n",
        "    # Get the indices of non-zero pixels from the original saliency video\n",
        "    indices = np.argwhere(saliency_video)\n",
        "\n",
        "    # Create a list of tuples containing the saliency value and the corresponding indices\n",
        "    saliency_video_value_with_indices = [\n",
        "        (flatten_saliency_video[i], indices[i])\n",
        "        for i in range(0, len(flatten_saliency_video))\n",
        "    ]  # List of [saliency_value_of_pixel, [t, x, y]]\n",
        "\n",
        "    # Sort the list by saliency value in ascending order, using the indices as a secondary criterion\n",
        "    sorted_saliency_video_for_importance_with_indices = sorted(\n",
        "        saliency_video_value_with_indices,\n",
        "        key=lambda x: (x[0], -x[1])  # Sort by saliency_value_of_pixel\n",
        "    )\n",
        "\n",
        "    # Return the sorted list in descending order of importance\n",
        "    return sorted_saliency_video_for_importance_with_indices[::-1]"
      ],
      "metadata": {
        "id": "rUdjcHJk8X8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Insertion***"
      ],
      "metadata": {
        "id": "c8RUj2Sz8fJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import copy\n",
        "\n",
        "def update_image_with_important_pixel(image, initial_image, frame, x, y):\n",
        "    \"\"\"\n",
        "    Update the image by inserting the most important pixel.\n",
        "\n",
        "    :param image: Current image.\n",
        "    :param initial_image: Original image.\n",
        "    :param frame: Frame number to insert into the image.\n",
        "    :param x: Spatial x-coordinate of the pixel.\n",
        "    :param y: Spatial y-coordinate of the pixel.\n",
        "    :return: Updated image.\n",
        "    \"\"\"\n",
        "    new_image = copy.deepcopy(image)\n",
        "    new_image[frame][x, y] = initial_image[frame][x, y]  # Corrected the operator\n",
        "    return new_image\n",
        "\n",
        "def insertion(models, original_images, x3, pixel_sorted_by_saliency_value_with_indices, initial_blurred_images):\n",
        "    \"\"\"\n",
        "    Calculate the insertion metric for a given explanation.\n",
        "\n",
        "    :param models: List of pretrained models.\n",
        "    :param original_images: Original image.\n",
        "    :param x3: One-hot encoding for prediction.\n",
        "    :param pixel_sorted_by_saliency_value_with_indices: Indices of pixels in order of importance.\n",
        "    :param initial_blurred_images: Initial image with all pixels set to zero.\n",
        "    :return: List of errors at each insertion step.\n",
        "    \"\"\"\n",
        "\n",
        "    # Original prediction\n",
        "    original_prediction = ensemble_predict(models, original_images, x3)[0]\n",
        "    print(\"Original prediction:\", original_prediction)\n",
        "\n",
        "    # List to store images with gradually added frames\n",
        "    insertion_images = [initial_blurred_images.copy()]\n",
        "\n",
        "    # Prediction on the initial image (all pixels blurred)\n",
        "    I_prime = initial_blurred_images.copy()\n",
        "\n",
        "    # Gradually add the most important pixels frame by frame\n",
        "    for _, pixel_with_indices in pixel_sorted_by_saliency_value_with_indices:\n",
        "        frame, x, y = pixel_with_indices  # Extract frame (t), x and y\n",
        "        I_prime = update_image_with_important_pixel(I_prime, original_images, frame, x, y)\n",
        "        insertion_images.append(I_prime)\n",
        "\n",
        "    # Calculate predictions on images with gradually added frames\n",
        "    new_predictions = ensemble_predict(models, insertion_images, x3)\n",
        "\n",
        "    # Calculate MSE with respect to each new prediction\n",
        "    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions[1:]]\n",
        "    initial_error = mean_squared_error(original_prediction, new_predictions[0])  # MSE of the blurred image\n",
        "    print(f\"Initial Prediction with ALL Blurred pixel, pred: {new_predictions[0]}, error: {initial_error}\")\n",
        "\n",
        "    for t, error in enumerate(errors):\n",
        "        t_f, t_x, t_y = pixel_sorted_by_saliency_value_with_indices[t][1]  # Extract frame and pixel coordinates\n",
        "        print(f\"Insert pixel in frame {t_f} at position ({t_x},{t_y}), new prediction: {new_predictions[t + 1]}, error: {error}\")\n",
        "\n",
        "    total_errors = [initial_error] + errors\n",
        "    # Normalize the fraction of inserted pixels\n",
        "    x = [i / (len(pixel_sorted_by_saliency_value_with_indices) + 1) for i in range(len(total_errors))]\n",
        "\n",
        "    # Calculate the AUC\n",
        "    auc = calculate_auc(x, total_errors)\n",
        "    print(f\"Area under the curve (AUC): {auc}\")\n",
        "\n",
        "    # Plot the error curve and area under the curve (AUC)\n",
        "    plt.plot(x, total_errors, label='Error curve')\n",
        "    plt.fill_between(x, total_errors, color='skyblue', alpha=0.4)\n",
        "    plt.text(x[-1] * 0.95, max(total_errors) * 0.9, f'AUC: {auc:.2f}', horizontalalignment='right')\n",
        "    plt.xlabel('Fraction of pixels inserted')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.title('Insertion Metric Curve')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return total_errors, auc\n"
      ],
      "metadata": {
        "id": "-bXdn8dP8fx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_errors_from_insertion(test_image, test_OHE, nr_instance, saliency_video, initial_blurred_images, models):\n",
        "  original_images = copy.deepcopy(test_image[nr_instance])\n",
        "  x3 = copy.deepcopy(test_OHE[nr_instance])\n",
        "\n",
        "  pixel_sorted_by_saliency_value_with_indices = get_flatten_saliency_video_ordered_by_importance(saliency_video)\n",
        "\n",
        "  errors,auc = insertion(models, original_images, x3, pixel_sorted_by_saliency_value_with_indices, initial_blurred_images)\n",
        "\n",
        "  return errors,auc"
      ],
      "metadata": {
        "id": "xx2pyfAI9pW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Deletion***"
      ],
      "metadata": {
        "id": "79ggqcS89rmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import copy  # Importing the copy module to create deep copies of images\n",
        "\n",
        "def update_image_by_removing_pixel(image, frame, x, y):\n",
        "    \"\"\"\n",
        "    Update the image by removing the most important pixels.\n",
        "\n",
        "    :param image: Current image.\n",
        "    :param frame: Frame number to modify in the image.\n",
        "    :param x: Spatial coordinate x of the pixel.\n",
        "    :param y: Spatial coordinate y of the pixel.\n",
        "    :return: Updated image with the specified pixel removed.\n",
        "    \"\"\"\n",
        "    new_image = copy.deepcopy(image)  # Create a deep copy of the image to avoid modifying the original\n",
        "    new_image[frame][x,y] =+ np.zeros((1,3))  # Set the pixel at (x, y) to zero (black)\n",
        "\n",
        "    return new_image\n",
        "\n",
        "def deletion(models, original_images, x3, saliency_video, pixel_sorted_by_saliency_value_with_indices):\n",
        "    \"\"\"\n",
        "    Calculate the deletion metric for a given explanation.\n",
        "\n",
        "    :param models: List of pre-trained models.\n",
        "    :param original_images: Original image.\n",
        "    :param x3: One-hot encoding for the prediction.\n",
        "    :param pixel_sorted_by_saliency_value_with_indices: Indices of pixels in order of importance.\n",
        "    :return: List of errors at each removal step.\n",
        "    \"\"\"\n",
        "    # Get the original prediction from the ensemble of models\n",
        "    original_prediction = ensemble_predict(models, original_images, x3).flatten()\n",
        "    print(\"Original prediction:\", original_prediction)\n",
        "\n",
        "    # List to store images after gradually removing frames\n",
        "    deletions_images = []\n",
        "\n",
        "    # Initialize the modified image as a copy of the original\n",
        "    I_prime = original_images.copy()\n",
        "\n",
        "    # Gradually remove the most important pixels for each frame\n",
        "    for _, pixel_with_indices in pixel_sorted_by_saliency_value_with_indices:\n",
        "        frame, x, y = pixel_with_indices  # Extract frame (t), x, and y coordinates\n",
        "\n",
        "        I_prime = update_image_by_removing_pixel(I_prime, frame, x, y)  # Update the image by removing the pixel\n",
        "        deletions_images.append(I_prime)  # Append the modified image to the list\n",
        "\n",
        "    # Calculate predictions for all modified images with pixels gradually removed\n",
        "    new_predictions = ensemble_predict(models, deletions_images, x3)\n",
        "    # Calculate the mean squared error (MSE) compared to the original prediction\n",
        "    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions]\n",
        "\n",
        "    initial_error = 0.0  # Initialize the initial error as zero (no error)\n",
        "    print(f\"Initial Prediction with Original Images, prediction: {original_prediction}, error: {initial_error}\")\n",
        "    for t, error in enumerate(errors):\n",
        "        t_f = pixel_sorted_by_saliency_value_with_indices[t][1][0]  # Frame number of the pixel removed\n",
        "        t_x = pixel_sorted_by_saliency_value_with_indices[t][1][1]  # X coordinate of the pixel removed\n",
        "        t_y = pixel_sorted_by_saliency_value_with_indices[t][1][2]  # Y coordinate of the pixel removed\n",
        "        print(f\"Remove pixel in frame {t_f} in pos ({t_x},{t_y}), new prediction: {new_predictions[t]}, error: {error}\")\n",
        "\n",
        "    total_errors = [initial_error] + errors  # Initial error + errors from all removed pixels\n",
        "\n",
        "    x = [i/4160 for i in range(0, 4161)]  # Create an array representing the fraction of pixels removed\n",
        "\n",
        "    # Calculate the area under the curve (AUC) for the error values\n",
        "    auc = calculate_auc(x, total_errors)\n",
        "    print(f\"Area under the curve (AUC): {auc}\")\n",
        "\n",
        "    # Plot the error curve and fill the area under the curve (AUC)\n",
        "    plt.plot(x, total_errors, label='Error curve')\n",
        "    plt.fill_between(x, total_errors, color='lightcoral', alpha=0.4)\n",
        "    # Position the AUC text to the right of the title\n",
        "    plt.text(1.02, 1.02, f'AUC: {auc:.2f}',\n",
        "         horizontalalignment='left',\n",
        "         transform=plt.gca().transAxes,  # Coordinates relative to the axes (from 0 to 1)\n",
        "         fontsize=11)\n",
        "    plt.xlabel('Fraction of pixels removed')  # Label for the x-axis\n",
        "    plt.ylabel('Mean Squared Error')  # Label for the y-axis\n",
        "    plt.title('Deletion Metric Curve')  # Title of the plot\n",
        "    plt.legend()  # Show the legend\n",
        "    plt.show()  # Display the plot\n",
        "\n",
        "    return total_errors, auc  # Return the total errors and the AUC value\n"
      ],
      "metadata": {
        "id": "0hYBEzzb9vGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_errors_from_deletion(test_image, test_OHE, nr_instance, saliency_video, models):\n",
        "  original_images = copy.deepcopy(test_image[nr_instance])\n",
        "  x3 = copy.deepcopy(test_OHE[nr_instance])\n",
        "\n",
        "  pixel_sorted_by_saliency_value_with_indices = get_flatten_saliency_video_ordered_by_importance(saliency_video)\n",
        "\n",
        "  errors,auc = deletion(models, original_images, x3, saliency_video, pixel_sorted_by_saliency_value_with_indices)\n",
        "\n",
        "  return errors,auc"
      ],
      "metadata": {
        "id": "qaAS0Lno9s39"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}